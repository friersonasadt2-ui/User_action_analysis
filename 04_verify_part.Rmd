---
title: "04_verify_part"
author: "Loih"
date: "2026-01-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("R/R_setup.R")
```

```{r}
options(datatable.fread.mmap = FALSE)
train_dt <- fread(file.path(dir_model, "train_set.csv"))
val_dt <- fread(file.path(dir_model, "val_set.csv"))
test_dt <- fread(file.path(dir_model, "test_set.csv"))
all_dt <- fread(file.path(dir_feat, "all_set_processed.csv"))

label_col <- "label_buy"

#定义排除列
leak_cols <- c("ui_buy","ui_buy_rate","ui_buy_1d","ui_buy_3d","ui_buy_7d")

exclude_cols <- c(
  "user_id","item_id","split", label_col,
  "u_pref_hour","u_pref_dow","i_cat",
  "u_first_time","u_last_time","i_first_time","i_last_time",
  "ui_first_time","ui_last_time","u_label_buy",
  leak_cols
)

#只对numeric且不在exclude里的列做筛选
feat_cols <- setdiff(names(train_dt)[sapply(train_dt, is.numeric)], exclude_cols)

#去掉零方差和常数特征
nzv <- feat_cols[sapply(feat_cols, function(cn) {
  x <- train_dt[[cn]]
  x <- x[is.finite(x)]
  length(x) == 0 || var(x, na.rm = TRUE) == 0
})]
feat_cols1 <- setdiff(feat_cols, nzv)

cat("Numeric feature candidates:", length(feat_cols), "\n")
cat("Remove zero-variance:", length(nzv), "\n")

#相关性过滤
corr_threshold <- 0.95

X <- as.matrix(train_dt[, ..feat_cols1])
C <- suppressWarnings(cor(X, use = "pairwise.complete.obs"))

idx <- which(abs(C) >= corr_threshold & upper.tri(C), arr.ind = TRUE)
corr_pairs <- data.table(
  f1 = rownames(C)[idx[,1]],
  f2 = colnames(C)[idx[,2]],
  corr = C[idx]
)
corr_pairs[, abs_corr := abs(corr)]
setorder(corr_pairs, -abs_corr)
corr_pairs[, abs_corr := NULL]

# “与标签相关性更强”的保留规则
y <- train_dt[[label_col]]
score_with_label <- function(cn) {
  x <- train_dt[[cn]]
  if (all(!is.finite(x))) return(0)
  suppressWarnings(abs(cor(x, y, use = "pairwise.complete.obs")))
}

to_drop_corr <- character(0)

if (nrow(corr_pairs) > 0) {
  for (i in seq_len(nrow(corr_pairs))) {
    a <- corr_pairs$f1[i]
    b <- corr_pairs$f2[i]
    if (a %in% to_drop_corr || b %in% to_drop_corr) next

    sa <- score_with_label(a); if (is.na(sa)) sa <- 0
    sb <- score_with_label(b); if (is.na(sb)) sb <- 0

    if (sa > sb) {
      to_drop_corr <- c(to_drop_corr, b)
    } else if (sb > sa) {
      to_drop_corr <- c(to_drop_corr, a)
    } else {
      va <- var(train_dt[[a]], na.rm = TRUE); if (is.na(va)) va <- 0
      vb <- var(train_dt[[b]], na.rm = TRUE); if (is.na(vb)) vb <- 0
      to_drop_corr <- c(to_drop_corr, ifelse(va >= vb, b, a))
    }
  }
}

to_drop_corr <- unique(to_drop_corr)

keep_cols <- setdiff(feat_cols, c(nzv, to_drop_corr))

fwrite(data.table(feature = keep_cols), file.path(dir_feat, "feature_keep_final.csv"))

cat("Features before:", length(feat_cols), "\n")
cat("Drop zero-var:", length(nzv), "\n")
cat("Drop by corr :", length(to_drop_corr), "\n")
cat("Keep final   :", length(keep_cols), "\n")

#输出filtered数据集
keep_all_cols <- c("user_id","item_id","split", label_col, keep_cols)

#只保留各表里实际存在的列
cols_train <- intersect(keep_all_cols, names(train_dt))
cols_val   <- intersect(keep_all_cols, names(val_dt))
cols_test  <- intersect(keep_all_cols, names(test_dt))
cols_all   <- intersect(keep_all_cols, names(all_dt))

train_keep <- train_dt[, ..cols_train]
val_keep   <- val_dt[,   ..cols_val]
test_keep  <- test_dt[,  ..cols_test]
all_keep   <- all_dt[,   ..cols_all]

fwrite(train_keep, file.path(dir_model,"train_set_filtered.csv"))
fwrite(val_keep, file.path(dir_model,"val_set_filtered.csv"))
fwrite(test_keep, file.path(dir_model,"test_set_filtered.csv"))
fwrite(all_keep, file.path(dir_feat,"all_set_filtered.csv"))

#过滤特征字典+按 dict_keep_features固定顺序排序
feat_dict <- fread(file.path(dir_dict,"feature_dictionary.csv"), encoding = "UTF-8")

# 确保feature列存在且为字符
stopifnot("feature" %in% names(feat_dict))
feat_dict[, feature := as.character(feature)]

#字典里保留：id/label/meta + keep_cols
dict_keep_features <- c("user_id","item_id","split", label_col, keep_cols)
dict_keep_features <- unique(dict_keep_features)

#先过滤
feat_dict_filtered <- feat_dict[feature %in% dict_keep_features]

#用“顺序列”排序
order_map <- data.table(feature = dict_keep_features, order_id = seq_along(dict_keep_features))
feat_dict_filtered <- merge(feat_dict_filtered, order_map, by = "feature", all.x = TRUE)

#给大值排最后
feat_dict_filtered[is.na(order_id), order_id := 999999L]

setorder(feat_dict_filtered, order_id)
feat_dict_filtered[, order_id := NULL]

fwrite(feat_dict_filtered, file.path(dir_dict,"feature_dictionary_filtered.csv"), bom = TRUE)


```


```{r}
#读取keep_cols
keep_cols <- fread(file.path(dir_dict, "feature_dictionary_filtered.csv"))$feature
keep_cols <- intersect(keep_cols, names(train_dt))

feat_cols <- setdiff(keep_cols, exclude_cols)
feat_cols <- feat_cols[sapply(train_dt[, ..feat_cols], is.numeric)]

#标签必须是0/1
train_dt[, (label_col) := as.integer(get(label_col))]
train_dt <- train_dt[get(label_col) %in% c(0L,1L)]

#单变量AUC
fast_auc <- function(score, y) {
  ok <- is.finite(score) & !is.na(y)
  score <- score[ok]
  y <- y[ok]
  y <- as.integer(y)
  n1 <- as.numeric(sum(y == 1L))
  n0 <- as.numeric(sum(y == 0L))
  if (n1 == 0 || n0 == 0) return(NA_real_)

  r <- rank(score, ties.method = "average")
  denom <- n1 * n0
  if (!is.finite(denom) || denom == 0) return(NA_real_)

  auc <- (sum(r[y == 1L]) - n1 * (n1 + 1) / 2) / denom
  as.numeric(auc)
}


#单变量IV(分箱+WOE/IV)
calc_iv_woe <- function(dt, x_col, y_col = "label_buy", n_bins = 10, eps = 0.5,
                        zero_bin = TRUE, zero_bin_ratio = 0.2) {
  stopifnot(x_col %in% names(dt), y_col %in% names(dt))

  tmp <- dt[, .(x = as.numeric(get(x_col)), y = as.integer(get(y_col)))]
  tmp <- tmp[is.finite(x) & y %in% c(0L, 1L)]
  if (nrow(tmp) == 0) return(list(iv = 0, detail = data.table()))

  #常数/几乎常数，IV=0
  if (uniqueN(tmp$x) <= 1) {
    tab <- tmp[, .(good = sum(y == 0L), bad = sum(y == 1L)), by = .(bin = "all")]
    tab[, `:=`(good = as.numeric(good), bad = as.numeric(bad))]
    tab[good == 0, good := eps]
    tab[bad  == 0, bad  := eps]
    G <- sum(tab$good); B <- sum(tab$bad)
    tab[, `:=`(dist_good = good / G, dist_bad = bad / B)]
    tab[, woe := log(dist_bad / dist_good)]
    tab[, iv_part := (dist_bad - dist_good) * woe]
    return(list(iv = 0, detail = tab))
  }

  #分箱
  x0_ratio <- mean(tmp$x == 0, na.rm = TRUE)

  #0很多让0单独一箱，非0再分箱
  if (zero_bin && x0_ratio >= zero_bin_ratio && any(tmp$x == 0)) {
    tmp[, bin := fifelse(x == 0, "0", NA_character_)]

    tmp[x != 0, bin := {
      x2 <- x
      qs <- unique(quantile(x2, probs = seq(0, 1, length.out = n_bins), na.rm = TRUE, type = 7))

      #分位点塌陷用rank分箱
      if (length(qs) < 3) {
        r <- frank(x2, ties.method = "average")
        qs2 <- unique(quantile(r, probs = seq(0, 1, length.out = n_bins), na.rm = TRUE, type = 7))
        if (length(qs2) < 3) {
          rep("nonzero", .N)
        } else {
          as.character(cut(r, breaks = qs2, include.lowest = TRUE, right = TRUE))
        }
      } else {
        as.character(cut(x2, breaks = qs, include.lowest = TRUE, right = TRUE))
      }
    }]

  } else {
    #普通分位数分箱
    qs <- unique(quantile(tmp$x, probs = seq(0, 1, length.out = n_bins + 1), na.rm = TRUE, type = 7))

    if (length(qs) < 3) {
      #分位点塌陷用rank分箱
      r <- frank(tmp$x, ties.method = "average")
      qs2 <- unique(quantile(r, probs = seq(0, 1, length.out = n_bins + 1), na.rm = TRUE, type = 7))
      if (length(qs2) < 3) {
        tmp[, bin := "all"]
      } else {
        tmp[, bin := as.character(cut(r, breaks = qs2, include.lowest = TRUE, right = TRUE))]
      }
    } else {
      tmp[, bin := as.character(cut(x, breaks = qs, include.lowest = TRUE, right = TRUE))]
    }
  }

  #如果最终只剩1个bin，IV=0
  if (uniqueN(tmp$bin) <= 1) {
    return(list(iv = 0, detail = data.table()))
  }

  #WOE/IV
  tab <- tmp[, .(
    good = sum(y == 0L, na.rm = TRUE),
    bad  = sum(y == 1L, na.rm = TRUE)
  ), by = bin]

  tab[, `:=`(good = as.numeric(good), bad = as.numeric(bad))]
  tab[good == 0, good := eps]
  tab[bad  == 0, bad  := eps]

  G <- sum(tab$good); B <- sum(tab$bad)
  if (!is.finite(G) || !is.finite(B) || G <= 0 || B <= 0) return(list(iv = 0, detail = tab))

  tab[, `:=`(
    dist_good = good / G,
    dist_bad  = bad  / B
  )]

  tab[, woe := log(dist_bad / dist_good)]
  tab[, iv_part := (dist_bad - dist_good) * woe]
  iv <- sum(tab$iv_part)
  if (!is.finite(iv)) iv <- 0

  list(iv = as.numeric(iv), detail = tab[order(-abs(woe))])
}

#单变量验证汇总表(AUC/IV和基本统计)
y <- train_dt[[label_col]]

uni_tbl <- rbindlist(lapply(feat_cols, function(cn) {
  x <- train_dt[[cn]]
  iv_res <- calc_iv_woe(train_dt, cn, y_col = label_col, n_bins = 10, eps = 0.5)

  data.table(
    feature = cn,
    n = length(x),
    na_rate = mean(!is.finite(x)),
    mean = suppressWarnings(mean(x, na.rm = TRUE)),
    sd   = suppressWarnings(sd(x, na.rm = TRUE)),
    auc  = fast_auc(x, y),
    iv   = iv_res$iv
  )
}), use.names = TRUE, fill = TRUE)

#输出到 validation_uni
fwrite(uni_tbl[order(-auc)], file.path(dir_uni, "univariate_auc_iv.csv"))


#单变量可视化(Top N)
dir_plot_uni <- file.path(dir_uni, "plots_univariate")
dir.create(dir_plot_uni, showWarnings = FALSE, recursive = TRUE)
topN <- 15
top_feats <- uni_tbl[order(-auc)][1:min(topN, .N), feature]

plot_one_feature <- function(cn) {
  tmp <- train_dt[, .(x = get(cn), y = factor(get(label_col)))]
  tmp <- tmp[is.finite(x)]

  p_hist <- ggplot(tmp, aes(x = x, fill = y)) +
    geom_histogram(bins = 40, alpha = 0.55, position = "identity") +
    labs(title = paste0("Histogram: ", cn), x = cn, fill = "label") +
    theme_minimal()

  p_box <- ggplot(tmp, aes(x = y, y = x, fill = y)) +
    geom_boxplot(outlier.alpha = 0.2) +
    labs(title = paste0("Boxplot: ", cn), x = "label", y = cn) +
    theme_minimal()

  ggsave(filename = file.path(dir_plot_uni, paste0("hist_", cn, ".png")),
         plot = p_hist, width = 7, height = 4)
  ggsave(filename = file.path(dir_plot_uni, paste0("box_", cn, ".png")),
         plot = p_box, width = 6, height = 4)
}
invisible(lapply(top_feats, plot_one_feature))


#特征重要性：Logistic 回归
topK <- min(35, length(feat_cols))
feat_for_logit <- uni_tbl[order(-auc)][1:topK, feature]

df_glm <- as.data.frame(train_dt[, c(label_col, feat_for_logit), with = FALSE])
df_glm[[label_col]] <- as.integer(df_glm[[label_col]])

fit <- glm(as.formula(paste(label_col, "~", paste(feat_for_logit, collapse = "+"))),
           data = df_glm, family = binomial())

sm <- summary(fit)$coefficients
imp_logit <- data.table(
  feature = rownames(sm),
  coef = sm[,1],
  se   = sm[,2],
  z    = sm[,3],
  p    = sm[,4]
)
imp_logit <- imp_logit[feature != "(Intercept)"]
imp_logit[, abs_z := abs(z)]
setorder(imp_logit, -abs_z)
imp_logit[, abs_z := NULL]

#输出到 model
fwrite(imp_logit, file.path(dir_multi, "importance_logit.csv"))


#置换重要性(Permutation importance)
predict_prob <- function(d) {
  p <- suppressWarnings(predict(fit, newdata = d, type = "response"))
  as.numeric(p)
}

base_score <- fast_auc(predict_prob(df_glm), df_glm[[label_col]])

perm_imp <- rbindlist(lapply(feat_for_logit, function(cn) {
  d2 <- copy(df_glm)
  d2[[cn]] <- sample(d2[[cn]], length(d2[[cn]]), replace = FALSE)
  auc2 <- fast_auc(predict_prob(d2), d2[[label_col]])
  data.table(feature = cn, auc_drop = base_score - auc2)
}))

setorder(perm_imp, -auc_drop)
fwrite(perm_imp, file.path(dir_multi, "importance_perm.csv"))


```

```{r}
drop_feats <- c(
  "u_hour_nunique",
  "ui_fav_rate",
  "u_day_nunique",
  "i_buy_1d",
  "u_buy_7d"
)

#读入数据
train_dt2 <- fread(file.path(dir_model,"train_set_filtered.csv"))
val_dt2 <- fread(file.path(dir_model,"val_set_filtered.csv"))
test_dt2 <- fread(file.path(dir_model,"test_set_filtered.csv"))
all_dt2 <- fread(file.path(dir_feat,"all_set_filtered.csv"))
feat_dict2 <- fread(file.path(dir_dict,"feature_dictionary_filtered.csv"), encoding = "UTF-8")

drop_cols <- function(dt, cols_to_drop) {
  cols_exist <- intersect(names(dt), cols_to_drop)
  if (length(cols_exist) > 0) dt[, (cols_exist) := NULL]
  dt
}


#删除数据列
train_dt_final <- drop_cols(copy(train_dt2), drop_feats)
val_dt_final <- drop_cols(copy(val_dt2), drop_feats)
test_dt_final <- drop_cols(copy(test_dt2), drop_feats)
all_dt_final <-drop_cols(copy(all_dt2), drop_feats)

#删除字典中的对应行
feat_col <- if ("feature" %in% names(feat_dict2)) "feature"
feat_dict_final <- feat_dict2[!(get(feat_col) %in% drop_feats)]

#保存
fwrite(train_dt_final, file.path(dir_model, "train_set_final.csv"))
fwrite(val_dt_final, file.path(dir_model, "val_set_final.csv"))
fwrite(test_dt_final, file.path(dir_model, "test_set_final.csv"))
fwrite(all_dt_final, file.path(dir_feat, "all_set_final.csv"))
fwrite(feat_dict_final, file.path(dir_dict, "feature_dictionary_final.csv"), bom = TRUE)



```










